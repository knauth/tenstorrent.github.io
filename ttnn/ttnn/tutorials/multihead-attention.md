<a id="multi-head-attention"></a>

# Multi-Head Attention

* [Multi-Head Attention](ttnn_tutorials/003.md)
  * [Enable program cache](ttnn_tutorials/003.md#Enable-program-cache)
  * [Write Multi-Head Attention using ttnn](ttnn_tutorials/003.md#Write-Multi-Head-Attention-using-ttnn)
  * [Configuration](ttnn_tutorials/003.md#Configuration)
  * [Initialize activations and weights using torch](ttnn_tutorials/003.md#Initialize-activations-and-weights-using-torch)
  * [Convert activations and weights to ttnn](ttnn_tutorials/003.md#Convert-activations-and-weights-to-ttnn)
  * [Run the first iteration of Multi-Head Attention](ttnn_tutorials/003.md#Run-the-first-iteration-of-Multi-Head-Attention)
  * [Run a subsequent iteration of Multi-Head Attention](ttnn_tutorials/003.md#Run-a-subsequent-iteration-of-Multi-Head-Attention)
  * [Write optimized version of Multi-Head Attention](ttnn_tutorials/003.md#Write-optimized-version-of-Multi-Head-Attention)
  * [Pre-process the parameters of the optimized model](ttnn_tutorials/003.md#Pre-process-the-parameters-of-the-optimized-model)
  * [Run the first iteration of the optimized Multi-Head Attention](ttnn_tutorials/003.md#Run-the-first-iteration-of-the-optimized-Multi-Head-Attention)
  * [Run a subsequent iteration of the optimized Multi-Head Attention](ttnn_tutorials/003.md#Run-a-subsequent-iteration-of-the-optimized-Multi-Head-Attention)
  * [Check that the output of the optimized version matches the output of the original implementation](ttnn_tutorials/003.md#Check-that-the-output-of-the-optimized-version-matches-the-output-of-the-original-implementation)
  * [Close the device](ttnn_tutorials/003.md#Close-the-device)
